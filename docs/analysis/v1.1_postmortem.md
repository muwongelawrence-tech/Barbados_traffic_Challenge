# v1.1 Post-Mortem Analysis

## Scores
- **v1.0**: 0.4612 (all "free flowing")
- **v1.1**: 0.3024 (50% "free flowing", 50% "heavy delay")
- **Drop**: -0.1588 (-34.4%)

## What Happened?

### The Fatal Flaw

**SMOTE balanced the training data, but the test set remained imbalanced!**

#### v1.0 Predictions
```
free flowing: 880 (100%)
```
- Simple strategy: predict most common class
- Matched test distribution (likely ~95% free flowing like training)
- **Result**: Decent score (0.4612)

#### v1.1 Predictions  
```
free flowing: 440 (50%)
heavy delay:  440 (50%)
```
- SMOTE created balanced training set (25% each class)
- Model learned to predict all classes equally
- But test set is still imbalanced!
- **Result**: Worse score (0.3024) - predicting delays when there aren't any

### Root Cause Analysis

1. **Training Distribution** (Enter Rating):
   - free flowing: 63%
   - delays: 37%

2. **After SMOTE**:
   - All classes: 25% each (perfectly balanced)

3. **Model Behavior**:
   - Learned to predict delays more often
   - Became "confident" about minority classes
   - Lost the natural bias toward "free flowing"

4. **Test Reality**:
   - Likely similar to training: ~60-95% free flowing
   - Model predicting 50% delays = MANY false positives
   - Each false positive hurts the score

### The Paradox

**v1.0's "weakness" was actually its strength!**

- v1.0 predicted only "free flowing" (seemed bad)
- But if test is 95% free flowing, v1.0 gets 95% right!
- v1.1 predicts 50% delays, but if only 5% are delays:
  - Gets ~45% wrong (false positives)
  - Score drops significantly

## Mathematical Analysis

Assuming test set is 90% free flowing, 10% delays:

**v1.0 Performance**:
- Predicts all "free flowing"
- Accuracy: 90% (all free flowing correct, all delays wrong)
- **Estimated score: ~0.45-0.50** ✅ Matches actual 0.4612

**v1.1 Performance**:
- Predicts 50% free flowing, 50% delays
- Free flowing: Gets ~45% right (50% of 90%)
- Delays: Gets ~5% right (50% of 10%)
- Accuracy: ~50%
- **Estimated score: ~0.30-0.35** ✅ Matches actual 0.3024

## Key Lessons Learned

### ❌ What Didn't Work
1. **SMOTE for imbalanced test sets**
   - Balances training, not test
   - Creates unrealistic expectations
   - Model overfits to balanced distribution

2. **Forcing diversity in predictions**
   - Test set distribution ≠ balanced
   - Predicting rare classes too often = false positives
   - Hurts overall accuracy

3. **Ignoring class distribution**
   - Training shows 63% free flowing
   - Should maintain this bias, not eliminate it

### ✅ What We Learned
1. **Respect the natural distribution**
   - If training is imbalanced, test likely is too
   - Don't force balance where it doesn't exist

2. **Simple baselines are powerful**
   - "Predict most common class" = 0.4612
   - Complex SMOTE approach = 0.3024
   - Simpler was better!

3. **Class imbalance strategies must match deployment**
   - SMOTE works when test is balanced
   - For imbalanced test: use class weights, not resampling
   - Or adjust decision thresholds

## Corrective Actions

### Immediate (v1.2)
1. **Revert SMOTE** - Don't use oversampling
2. **Use class weights** instead:
   ```python
   class_weight='balanced'  # Penalizes errors, doesn't resample
   ```
3. **Adjust decision threshold**:
   - Use predict_proba()
   - Only predict "delay" if probability > 0.7 (high confidence)
   - Default to "free flowing" otherwise

### Medium Term (v1.3+)
1. **Better feature engineering**
   - Features that distinguish delays from free flowing
   - Time-based patterns (rush hour, etc.)

2. **Ensemble with conservative bias**
   - Combine models
   - Bias toward "free flowing" in final prediction

3. **Calibrated probabilities**
   - Use Platt scaling or isotonic regression
   - Better probability estimates

## Recommendations for v1.2

```python
# DON'T DO THIS (v1.1):
smote = SMOTE()
X_train, y_train = smote.fit_resample(X, y)

# DO THIS INSTEAD (v1.2):
model = LGBMClassifier(
    class_weight='balanced',  # Weights, not resampling
    ...
)

# OR use custom weights favoring majority class:
from sklearn.utils.class_weight import compute_class_weight
weights = compute_class_weight('balanced', classes=np.unique(y), y=y)
# Then scale down minority class weights by 0.5
weights[1:] *= 0.5  # Less aggressive balancing
```

## Updated Strategy

1. **Accept the imbalance** - Test is imbalanced like training
2. **Predict conservatively** - Bias toward "free flowing"
3. **High threshold for delays** - Only predict when very confident
4. **Focus on features** - Better features > better sampling
5. **Validate properly** - Use stratified CV that maintains distribution

## Expected v1.2 Score

With conservative approach:
- **Target**: 0.50-0.55 (improvement from v1.0: 0.4612)
- **Strategy**: Predict mostly "free flowing", delays only when confident
- **Method**: Class weights + probability thresholding
